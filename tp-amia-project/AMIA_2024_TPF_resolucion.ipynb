{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Implementación Base\n",
    "#### 1. \n",
    "Pita: comparar con las distribuciones del dataset completo, **sin splitear**"
   ],
   "id": "51844b72cbcfaca6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:37.269489Z",
     "start_time": "2024-08-13T02:47:36.545398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from utils import ClassEncoder\n",
    "from datasets import get_iris_dataset\n",
    "X_full_iris, y_full_iris = get_iris_dataset()\n",
    "print(X_full_iris.shape)\n",
    "print(y_full_iris.shape)"
   ],
   "id": "a3cf4012d20e8b98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 1)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:37.296264Z",
     "start_time": "2024-08-13T02:47:37.291355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_distribution(_y):\n",
    "    encoder = ClassEncoder()\n",
    "    encoded_y = encoder.fit_transform(_y) # convert class to number (encode)\n",
    "    print('Distribución de clases:')\n",
    "    distribution = np.bincount(encoded_y.flatten())/len(encoded_y)\n",
    "    for class_name, value in zip(encoder.names, distribution):\n",
    "        print(f'{class_name}: {value:.4f}')\n",
    "\n",
    "print_distribution(y_full_iris)\n"
   ],
   "id": "b83ef9c952b426af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases:\n",
      "setosa: 0.3333\n",
      "versicolor: 0.3333\n",
      "virginica: 0.3333\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Se observa que el dataset Iris se encuentra balanceado, es decir que no hay alguna preponderancia por sobre alguna de las clases. Esto es una característica deseada ya que si tuvieramos un desbalance, por ejemplo 90% de una de las tres clases, nuestro modelo no generaliza bien, es decir es muy probable que caiga en overfitting.",
   "id": "767fec1ed536e345"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1) QDA Entrenado con:  probabilidades a priori uniforme y  una clase con probabilidad 0.9, las demás 0.05 ( 3 combinaciones)",
   "id": "4b6de399ab132490"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:37.480657Z",
     "start_time": "2024-08-13T02:47:37.443616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import split_transpose, QDA, accuracy\n",
    "\n",
    "def priori_test(dataset):\n",
    "    X_full, y_full = dataset\n",
    "    a_priori_A = [1/3, 1/3, 1/3]\n",
    "    a_priori_B_1 = [0.9, 0.05, 0.05]\n",
    "    a_priori_B_2 = [0.05, 0.9, 0.05]\n",
    "    a_priori_B_3 = [0.05, 0.05, 0.9]\n",
    "    \n",
    "    a_priori_list = [a_priori_A, a_priori_B_1, a_priori_B_2, a_priori_B_3]\n",
    "    # from utils import QDA\n",
    "    # rng_seed = 6543\n",
    "    train_x, train_y, test_x, test_y = split_transpose(X_full, y_full, 0.4, 6543)\n",
    "    \n",
    "    for i,_a_priori in enumerate(a_priori_list):\n",
    "        model = QDA()\n",
    "        model.fit(train_x, train_y, _a_priori)\n",
    "        print('A prioris:')\n",
    "        print(\",\".join([f' {class_name}:{p:.3f} ' for class_name, p in zip(model.encoder.names, _a_priori)]))\n",
    "        train_acc = accuracy(train_y, model.predict(train_x))\n",
    "        test_acc = accuracy(test_y, model.predict(test_x))\n",
    "        print(f\"[Model {i}] Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")\n",
    "        # print('\\n')\n",
    "\n",
    "priori_test(get_iris_dataset())"
   ],
   "id": "4fbc6833c5a1e73b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prioris:\n",
      " setosa:0.333 , versicolor:0.333 , virginica:0.333 \n",
      "[Model 0] Train (apparent) error is 0.0222 while test error is 0.0167\n",
      "A prioris:\n",
      " setosa:0.900 , versicolor:0.050 , virginica:0.050 \n",
      "[Model 1] Train (apparent) error is 0.0222 while test error is 0.0167\n",
      "A prioris:\n",
      " setosa:0.050 , versicolor:0.900 , virginica:0.050 \n",
      "[Model 2] Train (apparent) error is 0.0333 while test error is 0.0000\n",
      "A prioris:\n",
      " setosa:0.050 , versicolor:0.050 , virginica:0.900 \n",
      "[Model 3] Train (apparent) error is 0.0333 while test error is 0.0500\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A partir de estos datos, se pueden hacer las siguientes suposiciones:\n",
    "- El modelo 0 y el modelo 1 cometen el mismo grado de error al hacer dichas suposiciones sobre los priors.\n",
    "- El modelo 2 parecería sobreajustar (hay overfitting) a los datos de test.\n",
    "- El modelo 3 tiene un mayor error tanto en el entrenamiento como en la prueba, lo que indica que no logra generalizar y que dichos priors tiene un efecto detrimental en la performance del modelo. "
   ],
   "id": "7c22fb5b463cbbbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2) Repetir punto 1 para el dataset penguin",
   "id": "e4691e2c3b5a69f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:37.772793Z",
     "start_time": "2024-08-13T02:47:37.503796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import get_penguins\n",
    "X_full_penguin, y_full_penguin = get_penguins()\n",
    "\n",
    "print_distribution(y_full_penguin)"
   ],
   "id": "4263ac5f7974baf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases:\n",
      "Adelie: 0.4415\n",
      "Chinstrap: 0.1988\n",
      "Gentoo: 0.3596\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Como podemos observar este dataset no esta balanceado con respecto a la cantidad de datos por clase.",
   "id": "7a07fb8018fb6aca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:37.862391Z",
     "start_time": "2024-08-13T02:47:37.790629Z"
    }
   },
   "cell_type": "code",
   "source": "priori_test(get_penguins())",
   "id": "44318e84b2b475f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A prioris:\n",
      " Adelie:0.333 , Chinstrap:0.333 , Gentoo:0.333 \n",
      "[Model 0] Train (apparent) error is 0.0098 while test error is 0.0073\n",
      "A prioris:\n",
      " Adelie:0.900 , Chinstrap:0.050 , Gentoo:0.050 \n",
      "[Model 1] Train (apparent) error is 0.0195 while test error is 0.0219\n",
      "A prioris:\n",
      " Adelie:0.050 , Chinstrap:0.900 , Gentoo:0.050 \n",
      "[Model 2] Train (apparent) error is 0.0098 while test error is 0.0219\n",
      "A prioris:\n",
      " Adelie:0.050 , Chinstrap:0.050 , Gentoo:0.900 \n",
      "[Model 3] Train (apparent) error is 0.0098 while test error is 0.0073\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:37.891553Z",
     "start_time": "2024-08-13T02:47:37.888900Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "70752dd5c89562d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3 Implementar LDA",
   "id": "e1b5275361fad988"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:37.936316Z",
     "start_time": "2024-08-13T02:47:37.932076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import BaseBayesianClassifier, inv,det\n",
    "\n",
    "class LDA(BaseBayesianClassifier):\n",
    "\n",
    "  def _fit_params(self, X, y):\n",
    "    #self.inv_cov = inv(np.cov(X, bias=True))\n",
    "    # creo q esto deberia ser ponderado por el promedio\n",
    "    self.inv_cov = inv(np.cov(X, bias=True))\n",
    "    \n",
    "    self.means = [X[:,y.flatten()==idx].mean(axis=1, keepdims=True) for idx in range(len(self.log_a_priori))]\n",
    "\n",
    "\n",
    "  def _predict_log_conditional(self, x, class_idx):\n",
    "    # predict the log(P(x|G=class_idx)), the log of the conditional probability of x given the class\n",
    "    # this should depend on the model used\n",
    "    unbiased_x =  x - self.means[class_idx]\n",
    "    return 0.5*np.log(det(self.inv_cov)) -0.5 * unbiased_x.T @ self.inv_cov @ unbiased_x"
   ],
   "id": "9bf258ed0b1a69a3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Comparar LDA vs QDA (Sin multiples prioris, es decir que se estime automaticamente las prioris) con los dos datasets\n",
   "id": "4b3349622de5cd6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:38.043952Z",
     "start_time": "2024-08-13T02:47:37.984166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name,dataset in zip(['iris', 'penguins'],[get_iris_dataset(), get_penguins()]):\n",
    "    for model_name, curr_model in zip(['QDA', 'LDA'],[QDA, LDA]):\n",
    "        model = curr_model()\n",
    "        x_full, y_full = dataset\n",
    "        train_x, train_y, test_x, test_y = split_transpose(x_full, y_full, 0.4, 6543)\n",
    "        model.fit(train_x, train_y)\n",
    "        train_acc = accuracy(train_y, model.predict(train_x))\n",
    "        test_acc = accuracy(test_y, model.predict(test_x))\n",
    "        print(f\"[Dataset={dataset_name}][Model={model_name}] train err {1-train_acc:.4f}, test err {1-test_acc:.4f}\")\n",
    "        \n",
    "    "
   ],
   "id": "5afccf7c21a27a1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset=iris][Model=QDA] train err 0.0111, test err 0.0167\n",
      "[Dataset=iris][Model=LDA] train err 0.1222, test err 0.2000\n",
      "[Dataset=penguins][Model=QDA] train err 0.0146, test err 0.0146\n",
      "[Dataset=penguins][Model=LDA] train err 0.0195, test err 0.0219\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Se puede ver que en ambos dataset QDA suele performar mejor, pero no por mucho.",
   "id": "121d4222bfffcc0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Utilizar otros 2 (dos) valores de *random seed* para obtener distintos splits de train y test, y repetir la comparación del punto anterior ¿Las conclusiones previas se mantienen?",
   "id": "60c4b6726cf49c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:38.360621Z",
     "start_time": "2024-08-13T02:47:38.086970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for dataset_name,dataset in zip(['iris', 'penguins'],[get_iris_dataset(), get_penguins()]):\n",
    "    for model_name, curr_model in zip(['QDA', 'LDA'],[QDA, LDA]):\n",
    "        for seed in [6543, 5501,125]:\n",
    "            model = curr_model()\n",
    "            x_full, y_full = dataset\n",
    "            train_x, train_y, test_x, test_y = split_transpose(x_full, y_full,test_sz=0.4, random_state=seed)\n",
    "            model.fit(train_x, train_y)\n",
    "            train_acc = accuracy(train_y, model.predict(train_x))\n",
    "            test_acc = accuracy(test_y, model.predict(test_x))\n",
    "            # print(f\"[Dataset={dataset_name}][Model={model_name}] train err {1-train_acc:.4f}, test err {1-test_acc:.4f}\")\n",
    "            row = {\n",
    "                'Dataset': dataset_name,\n",
    "                'Model': model_name,\n",
    "                'seed': seed,\n",
    "                'Error (train)': 1-train_acc,\n",
    "                'Error (test)': 1-test_acc,\n",
    "            }\n",
    "            \n",
    "            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "print(df)\n",
    "    "
   ],
   "id": "7a470151e2b2562f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Dataset Model  seed  Error (train)  Error (test)\n",
      "0       iris   QDA  6543       0.011111      0.016667\n",
      "1       iris   QDA  5501       0.022222      0.016667\n",
      "2       iris   QDA   125       0.022222      0.016667\n",
      "3       iris   LDA  6543       0.122222      0.200000\n",
      "4       iris   LDA  5501       0.155556      0.150000\n",
      "5       iris   LDA   125       0.155556      0.116667\n",
      "6   penguins   QDA  6543       0.014634      0.014599\n",
      "7   penguins   QDA  5501       0.014634      0.007299\n",
      "8   penguins   QDA   125       0.009756      0.014599\n",
      "9   penguins   LDA  6543       0.019512      0.021898\n",
      "10  penguins   LDA  5501       0.019512      0.021898\n",
      "11  penguins   LDA   125       0.019512      0.021898\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:38.394522Z",
     "start_time": "2024-08-13T02:47:38.391794Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "140be1e3bfa009a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5 Tensorized QDA vs QDA",
   "id": "a37a8736a93b6bc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:38.459553Z",
     "start_time": "2024-08-13T02:47:38.448819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import TensorizedQDA\n",
    "\n",
    "x_full, y_full = get_iris_dataset()\n",
    "train_x, train_y, test_x, test_y = split_transpose(x_full, y_full,test_sz=0.4, random_state=6543)\n",
    "\n",
    "tqda = TensorizedQDA()\n",
    "tqda.fit(train_x, train_y)\n",
    "train_acc = accuracy(train_y, tqda.predict(train_x))\n",
    "test_acc = accuracy(test_y, tqda.predict(test_x))\n",
    "\n",
    "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")"
   ],
   "id": "d9d5e4c3036eca76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0111 while test error is 0.0167\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:38.506285Z",
     "start_time": "2024-08-13T02:47:38.503975Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d01df6d45ab0a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:46.816203Z",
     "start_time": "2024-08-13T02:47:38.552319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "tqda.predict(test_x)"
   ],
   "id": "ab0347e9246ad3bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.03 ms ± 8.75 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:46.902856Z",
     "start_time": "2024-08-13T02:47:46.890697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qda = QDA()\n",
    "qda.fit(train_x, train_y)\n",
    "train_acc = accuracy(train_y, qda.predict(train_x))\n",
    "test_acc = accuracy(test_y, qda.predict(test_x))\n",
    "print(f\"Train (apparent) error is {1-train_acc:.4f} while test error is {1-test_acc:.4f}\")"
   ],
   "id": "7970b3217fa7540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (apparent) error is 0.0111 while test error is 0.0167\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:49.298448Z",
     "start_time": "2024-08-13T02:47:47.013962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%timeit\n",
    "\n",
    "qda.predict(test_x)"
   ],
   "id": "9fae0163b9d8c14f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 ms ± 65.4 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:49.379366Z",
     "start_time": "2024-08-13T02:47:49.377086Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d5728d52fd32a874",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Faster QDA",
   "id": "e88475da94ee1081"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T04:39:21.806855Z",
     "start_time": "2024-08-13T04:39:21.798014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import TensorizedQDA\n",
    "class FasterQDA(TensorizedQDA):\n",
    "    \n",
    "    def augment_dim(self, vec):\n",
    "        return np.array([np.repeat(vec[i], 90) for i in range(len(self.log_a_priori))])\n",
    "        \n",
    "    \n",
    "    def _predict_log_conditionals(self, x):\n",
    "        # train_x era de 4x90\n",
    "        # despues de hacer fit -> x es un tensor de 3 x 4 x 90 (o sea mismo array, 3 veces)\n",
    "        # (hacemos la prediccion para las 3 clases en conjunto)\n",
    "        unbiased_x = x - self.tensor_means\n",
    "        # unbiased_x.shape = k x p x n \n",
    "        print(unbiased_x.shape)\n",
    "        inner_prod = unbiased_x.transpose(0, 2, 1) @ self.tensor_inv_cov @ unbiased_x\n",
    "        # inner prod shape: (k, n, n) -> k matrices de nxn\n",
    "        # debemos de pensar que como es un producto de tensores => \n",
    "        # cada producto produce una matriz de nxn\n",
    "        \n",
    "        # dado un k fijo (estando parados en una clase)\n",
    "        # \n",
    "        \n",
    "        # podemos imaginar que en cada matriz\n",
    "        \n",
    "        # obtengo diagonal para cada matriz,\n",
    "        # ya que solo las que son consigo mismas son las que nos interesan (producto interno)\n",
    "        new_mat = np.array([np.diag(mat) for mat in inner_prod]) # (k,n)\n",
    "        itcov = np.log(det(self.tensor_inv_cov)) # (k,)\n",
    "        \n",
    "        # truco para no tener que crear un nuevo vector itcov de (k,n) para poder sumarlo\n",
    "        return 0.5 * itcov - 0.5 * new_mat.transpose() # (n,k)\n",
    "    def predict(self, X):\n",
    "        print(X.shape)        \n",
    "        log_cond = self._predict_log_conditionals(x) # (n,k)\n",
    "        log_priors = self.log_a_priori #(k,)\n",
    "        y_hat = self.encoder.names[np.argmax(log_priors + log_cond, axis=1)]\n",
    "        \n",
    "        return y_hat\n",
    "    \n",
    "fqda = FasterQDA()\n",
    "fqda.fit(train_x, train_y)\n",
    "fqda.predict(train_x)"
   ],
   "id": "a465a592ed10a61d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 90)\n",
      "(3, 4, 90)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:49.528525Z",
     "start_time": "2024-08-13T02:47:49.523652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n = 90 # obs\n",
    "p = 4 # features\n",
    "k = 3 # classes\n",
    "i_cov = np.ones((k,p,p)) # no se puede tocar\n",
    "x = np.ones((k,p,n))\n",
    "first = x.transpose(0,2,1)@i_cov\n",
    "print(f'{(x.transpose(0,2,1)).shape} x {i_cov.shape} = {first.shape}')\n",
    "print(f'{first.shape} x {x.shape} = {(first@x).shape} ')"
   ],
   "id": "82ddbeb2b41026f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 90, 4) x (3, 4, 4) = (3, 90, 4)\n",
      "(3, 90, 4) x (3, 4, 90) = (3, 90, 90) \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:49.574886Z",
     "start_time": "2024-08-13T02:47:49.572548Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "813d973d2121aeba",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T02:47:49.651510Z",
     "start_time": "2024-08-13T02:47:49.649460Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f7fc31b904b08858",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
